{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN Amazon Baby Review.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of the Review Attribute is : \n",
      "0.7642793999739596\n",
      "The Standard Deviation of the Review Attribute is : \n",
      "0.4244498007103935\n"
     ]
    }
   ],
   "source": [
    "#reading reviews using pandas library from amazon_baby_train.csv file\n",
    "reviews = pd.read_csv('amazon_baby_train.csv')\n",
    "reviews.shape\n",
    "\n",
    "# dropping observations which are incomplete\n",
    "reviews = reviews.dropna()\n",
    "reviews.shape\n",
    "\n",
    "# changing the reviews into positive and negative reviews\n",
    "scores = reviews['rating']\n",
    "reviews['rating'] = reviews['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# printing the mean and standard deviation of ratings\n",
    "print(\"The Mean of the Review Attribute is : \")\n",
    "print(scores.mean())\n",
    "print(\"The Standard Deviation of the Review Attribute is : \")\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitPosNeg(Summaries):\n",
    "    neg = reviews.loc[Summaries['rating'] == 0]\n",
    "    pos = reviews.loc[Summaries['rating'] == 1]\n",
    "    return [pos,neg]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the positive and negative review and storing them in separate arrays\n",
    "[pos,neg] = splitPosNeg(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing steps\n",
    "\n",
    "# Using lemmatizer to lemmatizze words\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# using stop words to remove the words which do not contribute to the sentiment\n",
    "stop = stopwords.words('english')\n",
    "translation = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "\n",
    "def preprocessing(line):\n",
    "    tokens=[]\n",
    "    line = line.translate(translation)\n",
    "    line = nltk.word_tokenize(line.lower())\n",
    "    #print(line)\n",
    "    stops = stopwords.words('english')\n",
    "    stops.remove('not')\n",
    "    stops.remove('no')\n",
    "    line = [word for word in line if word not in stops]\n",
    "    for t in line:\n",
    "        stemmed = lemmatizer.lemmatize(t)\n",
    "        tokens.append(stemmed)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Storing the positive and negative reviews in separate arrays\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "for p in pos['review']:\n",
    "    pos_data.append(preprocessing(p))\n",
    "\n",
    "for n in neg['review']:\n",
    "    neg_data.append(preprocessing(n))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['rating'].values,neg['rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizing each sentence from the file into words\n",
    "t = []\n",
    "for line in data:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55558\n"
     ]
    }
   ],
   "source": [
    "# Calculating the frequency dstribution of each word\n",
    "word_features = nltk.FreqDist(t)\n",
    "print(len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 80912), ('baby', 70749), ('one', 66194), ('love', 52997), ('great', 47666), ('like', 45664), ('would', 45661), ('use', 42480), ('seat', 39416), ('get', 38306), ('month', 34560), ('time', 33391), ('little', 33166), ('easy', 32862), ('old', 31945), ('well', 30745), ('product', 30585), ('really', 28026), ('also', 27756), ('son', 26691), ('bought', 25451), ('work', 25281), ('no', 24775), ('good', 23749), ('much', 23651)]\n"
     ]
    }
   ],
   "source": [
    "# The most common 200 words\n",
    "topwords = [fpair[0] for fpair in list(word_features.most_common(200))]\n",
    "print(word_features.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      words  count\n",
      "0       not  80912\n",
      "1      baby  70749\n",
      "2       one  66194\n",
      "3      love  52997\n",
      "4     great  47666\n",
      "5      like  45664\n",
      "6     would  45661\n",
      "7       use  42480\n",
      "8      seat  39416\n",
      "9       get  38306\n",
      "10    month  34560\n",
      "11     time  33391\n",
      "12   little  33166\n",
      "13     easy  32862\n",
      "14      old  31945\n",
      "15     well  30745\n",
      "16  product  30585\n",
      "17   really  28026\n",
      "18     also  27756\n",
      "19      son  26691\n"
     ]
    }
   ],
   "source": [
    "#printing the top 20 most common words\n",
    "word_his = pd.DataFrame(word_features.most_common(20), columns = ['words','count'])\n",
    "print(word_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the top words\n",
    "vec = CountVectorizer()\n",
    "c_fit = vec.fit_transform([' '.join(topwords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Tfidf Transformer on the data\n",
    "tf_vec = TfidfTransformer()\n",
    "tf_fit = tf_vec.fit_transform(c_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr_features = vec.transform(data)\n",
    "tr_features = tf_vec.transform(ctr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145927, 193)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "tr_features = tr_features.astype('int32')\n",
    "print(tr_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using KNN classifier to classify the data\n",
    "clf =  KNeighborsClassifier()\n",
    "clf = clf.fit(tr_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145927, 193)\n"
     ]
    }
   ],
   "source": [
    "lencheck= tr_features.shape\n",
    "print(lencheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct\n",
      "500\n",
      "Training Accuracy\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0;\n",
    "newlen = lencheck[0]-1\n",
    "for ch in range(0,newlen):\n",
    "    checkPrediction = clf.predict(tr_features[ch])\n",
    "    if(checkPrediction == [labels[ch]]):\n",
    "        num_correct = num_correct+1;\n",
    "print(\"Number of Correct\")\n",
    "print(num_correct)\n",
    "\n",
    "accuracy = (num_correct/newlen)*100;\n",
    "print(\"Training Accuracy\");\n",
    "print(accuracy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7622404476506569"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading reviews using pandas library from amazon_baby_test.csv file\n",
    "reviews = pd.read_csv('amazon_baby_test.csv')\n",
    "reviews.shape\n",
    "\n",
    "# dropping observations which are incomplete\n",
    "reviews = reviews.dropna()\n",
    "reviews.shape\n",
    "\n",
    "# changing the reviews into positive and negative reviews\n",
    "scores = reviews['rating']\n",
    "reviews['rating'] = reviews['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# calculating the mean of reviews\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the positive and negative review and storing them in separate arrays\n",
    "[pos,neg] = splitPosNeg(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Storing the positive and negative reviews in separate arrays\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "for p in pos['review']:\n",
    "    pos_data.append(preprocessing(p))\n",
    "\n",
    "for n in neg['review']:\n",
    "    neg_data.append(preprocessing(n))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining the positive and negative reviews\n",
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['rating'].values,neg['rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#tokenizing each sentence from the file into words\n",
    "t = []\n",
    "for line in data:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27828\n"
     ]
    }
   ],
   "source": [
    "# Calculating the frequency dstribution of each word\n",
    "word_features = nltk.FreqDist(t)\n",
    "print(len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 20502), ('baby', 17687), ('one', 16201), ('love', 13132), ('great', 11756), ('would', 11417), ('like', 11267), ('seat', 10442), ('use', 10437), ('get', 9549), ('month', 8510), ('little', 8383), ('time', 8267), ('easy', 8255), ('old', 7899), ('well', 7800), ('product', 7426), ('really', 6923), ('also', 6870), ('son', 6468), ('work', 6259), ('bought', 6186), ('no', 6051), ('good', 5950), ('much', 5944)]\n"
     ]
    }
   ],
   "source": [
    "# The most common 200 words\n",
    "topwords = [fpair[0] for fpair in list(word_features.most_common(200))]\n",
    "print(word_features.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the top words\n",
    "vec = CountVectorizer()\n",
    "c_fit = vec.fit_transform([' '.join(topwords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Tfidf Transformer on the data\n",
    "tf_vec = TfidfTransformer()\n",
    "tf_fit = tf_vec.fit_transform(c_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming the features using Tfidf transformer\n",
    "cte_features = vec.transform(data)\n",
    "te_features = tf_vec.transform(cte_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36457, 193)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct\n",
      "8\n",
      "Testing Accuracy\n",
      "80.0\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0;\n",
    "newlen = lencheck[0]-1\n",
    "for ch in range(0,newlen):\n",
    "    checkPrediction = clf.predict(te_features[ch])\n",
    "    if(checkPrediction == [labels[ch]]):\n",
    "        num_correct = num_correct+1;\n",
    "print(\"Number of Correct\")\n",
    "print(num_correct)\n",
    "\n",
    "accuracy = (num_correct/newlen)*100;\n",
    "print(\"Testing Accuracy\");\n",
    "print(accuracy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
