{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Amazon Baby Review\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean of the Review Attribute is : \n",
      "0.7642793999739596\n",
      "The Standard Deviation of the Review Attribute is : \n",
      "0.4244498007103935\n"
     ]
    }
   ],
   "source": [
    "#reading reviews using pandas library from amazon_baby_train.csv file\n",
    "reviews = pd.read_csv('amazon_baby_train.csv')\n",
    "reviews.shape\n",
    "\n",
    "# dropping observations which are incomplete\n",
    "reviews = reviews.dropna()\n",
    "reviews.shape\n",
    "\n",
    "# changing the reviews into positive and negative reviews\n",
    "scores = reviews['rating']\n",
    "reviews['rating'] = reviews['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# printing the mean and standard deviation of ratings\n",
    "print(\"The Mean of the Review Attribute is : \")\n",
    "print(scores.mean())\n",
    "print(\"The Standard Deviation of the Review Attribute is : \")\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0     34398\n",
       "1    111529\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping the reviews into positive and negative\n",
    "reviews.groupby('rating')['review'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14d41e496d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAF/CAYAAAAb/f6zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14d3cd6a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting a graph which counts the number of positive and negative labels\n",
    "reviews.groupby('rating')['review'].count().plot(kind='bar', color= ['r','g'],title='Label Distribution',  figsize = (10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the positive and negative review and storing them in separate arrays\n",
    "def splitPosNeg(Summaries):\n",
    "    neg = reviews.loc[Summaries['rating'] == 0]\n",
    "    pos = reviews.loc[Summaries['rating'] == 1]\n",
    "    return [pos,neg]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the positive and negative review and storing them in separate arrays\n",
    "[pos,neg] = splitPosNeg(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing steps\n",
    "\n",
    "# Using lemmatizer to lemmatizze words\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# using stop words to remove the words which do not contribute to the sentiment\n",
    "stop = stopwords.words('english')\n",
    "translation = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "\n",
    "def preprocessing(line):\n",
    "    tokens=[]\n",
    "    line = line.translate(translation)\n",
    "    line = nltk.word_tokenize(line.lower())\n",
    "    #print(line)\n",
    "    stops = stopwords.words('english')\n",
    "    stops.remove('not')\n",
    "    stops.remove('no')\n",
    "    line = [word for word in line if word not in stops]\n",
    "    for t in line:\n",
    "        stemmed = lemmatizer.lemmatize(t)\n",
    "        tokens.append(stemmed)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Storing the positive and negative reviews in separate arrays\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "for p in pos['review']:\n",
    "    pos_data.append(preprocessing(p))\n",
    "\n",
    "for n in neg['review']:\n",
    "    neg_data.append(preprocessing(n))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining the positive and negative reviews\n",
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['rating'].values,neg['rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizing each sentence from the file into words\n",
    "t = []\n",
    "for line in data:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55558\n"
     ]
    }
   ],
   "source": [
    "# Calculating the frequency dstribution of each word\n",
    "word_features = nltk.FreqDist(t)\n",
    "print(len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 80912), ('baby', 70749), ('one', 66194), ('love', 52997), ('great', 47666), ('like', 45664), ('would', 45661), ('use', 42480), ('seat', 39416), ('get', 38306), ('month', 34560), ('time', 33391), ('little', 33166), ('easy', 32862), ('old', 31945), ('well', 30745), ('product', 30585), ('really', 28026), ('also', 27756), ('son', 26691), ('bought', 25451), ('work', 25281), ('no', 24775), ('good', 23749), ('much', 23651)]\n"
     ]
    }
   ],
   "source": [
    "# The most common 5000 words\n",
    "topwords = [fpair[0] for fpair in list(word_features.most_common(5000))]\n",
    "print(word_features.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printing the top 200 most common words\n",
    "word_his = pd.DataFrame(word_features.most_common(200), columns = ['words','count'])\n",
    "#print(word_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the top words\n",
    "vec = CountVectorizer()\n",
    "c_fit = vec.fit_transform([' '.join(topwords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Tfidf Transformer on the data\n",
    "tf_vec = TfidfTransformer()\n",
    "tf_fit = tf_vec.fit_transform(c_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr_features = vec.transform(data)\n",
    "tr_features = tf_vec.transform(ctr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145927, 4973)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "tr_features = tr_features.astype('int32')\n",
    "print(tr_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Naive Bayes classifier to classify the data\n",
    "clf =  GaussianNB(priors=None)\n",
    "tr_features = tr_features.toarray()\n",
    "clf = clf.fit(tr_features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145927\n"
     ]
    }
   ],
   "source": [
    "lencheck= tr_features.shape\n",
    "print(lencheck[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-270e2c0511cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcheckPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckPrediction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_correct\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\nikhil\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\nikhil\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 dist = pairwise_distances(X, self._fit_X, 'euclidean',\n\u001b[0;32m--> 353\u001b[0;31m                                           n_jobs=n_jobs, squared=True)\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 dist = pairwise_distances(\n",
      "\u001b[0;32mC:\\nikhil\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\nikhil\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[1;31m# Special case to avoid picklability checks in delayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[1;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\nikhil\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \"Incompatible dimensions for Y and Y_norm_squared\")\n\u001b[1;32m    242\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_correct = 0;\n",
    "newlen = lencheck[0]-1\n",
    "\n",
    "for ch in range(0,1):\n",
    "    checkPrediction = clf.predict(tr_features[ch])\n",
    "    if(checkPrediction == [labels[ch]]):\n",
    "        num_correct = num_correct+1;\n",
    "print(\"Number of Correct\")\n",
    "print(num_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicting the output\n",
    "#tfPredication = clf.predict(tr_features)\n",
    "#tfAccuracy = metrics.accuracy_score(tfPredication,[labels])\n",
    "#print(tfAccuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing the metrics\n",
    "print(metrics.classification_report(labels, tfPredication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Testing Dataset\n",
    "\n",
    "# Reading reviews using pandas library from amazon_baby_test.csv file\n",
    "reviews = pd.read_csv('amazon_baby_test.csv')\n",
    "reviews.shape\n",
    "\n",
    "# dropping observations which are incomplete\n",
    "reviews = reviews.dropna()\n",
    "reviews.shape\n",
    "\n",
    "# changing the reviews into positive and negative reviews\n",
    "scores = reviews['rating']\n",
    "reviews['rating'] = reviews['rating'].apply(lambda x: '1' if x > 3 else '0')\n",
    "#print(reviews.head(25))\n",
    "\n",
    "# calculating the mean of reviews\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grouping the reviews into positive and negative\n",
    "reviews.groupby('rating')['review'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting a graph which counts the number of positive and negative labels\n",
    "reviews.groupby('rating')['review'].count().plot(kind='bar', color= ['r','g'],title='Label Distribution',  figsize = (10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the positive and negative review and storing them in separate arrays\n",
    "[pos,neg] = splitPosNeg(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Storing the positive and negative reviews in separate arrays\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "for p in pos['review']:\n",
    "    pos_data.append(preprocessing(p))\n",
    "\n",
    "for n in neg['review']:\n",
    "    neg_data.append(preprocessing(n))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining the positive and negative reviews\n",
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['rating'].values,neg['rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizing each sentence from the file into words\n",
    "t = []\n",
    "for line in data:\n",
    "    l = nltk.word_tokenize(line)\n",
    "    for w in l:\n",
    "        t.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the frequency dstribution of each word\n",
    "word_features = nltk.FreqDist(t)\n",
    "print(len(word_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The most common 5002 words\n",
    "topwords = [fpair[0] for fpair in list(word_features.most_common(5002))]\n",
    "print(word_features.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printing the top 200 most common words\n",
    "word_his = pd.DataFrame(word_features.most_common(200), columns = ['words','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the top words\n",
    "vec = CountVectorizer()\n",
    "c_fit = vec.fit_transform([' '.join(topwords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Tfidf Transformer on the data\n",
    "tf_vec = TfidfTransformer()\n",
    "tf_fit = tf_vec.fit_transform(c_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming the features using Tfidf transformer\n",
    "cte_features = vec.transform(data)\n",
    "te_features = tf_vec.transform(cte_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicting the output\n",
    "tePredication = clf.predict(te_features)\n",
    "teAccuracy = metrics.accuracy_score(tePredication,labels)\n",
    "print(teAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# printing the metrics\n",
    "print(metrics.classification_report(labels, tePredication))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
